version: '2.3'
# we should use 2.3 (because `runtime` parameter doesn't support it in v3)
# https://github.com/docker/compose/issues/5360#issuecomment-354354667

services:
  ai:
    build: .
#    command: /opt/conda/bin/jupyter notebook --notebook-dir=/opt/notebooks --allow-root --ip='*' --port=8888 --no-browser
    depends_on:
      - luigi_scheduler
      - mlflow_server
    environment:
    - MLFLOW_TRACKING_URI=http://mlflow_server:5000
    - NLTK_DATA=/var/datasets/0/nltk
    ports:
      - "8888:8888"
    volumes:
      - mlflow_artifacts:/artifacts
      - .:/opt/notebooks/
      - /var/datasets/:/var/datasets/
      - ~/.kaggle:/root/.kaggle
      # gensim has hardcoded place of its data (pretrained model)
      # https://github.com/RaRe-Technologies/gensim/blob/master/gensim/downloader.py#L66
      - /var/datasets/1/gensim-data:/root/gensim-data
      # we would store checkpoints and event files here
      - /var/models/:/var/models/
    restart: always
    runtime: nvidia
#    user: ${CURRENT_UID}

# TODO: setup db later
#
#  db:
#    image: postgres:9.5.4
#    ports:
#      - "5433:5432"
#    environment:
#      POSTGRES_USER: luigi
#      POSTGRES_DB: dev

  luigi_scheduler:
    build:
      context: luigi-scheduler
      dockerfile: Dockerfile
    ports:
      - "8082:8082"
    restart: always
#    depends_on:
#      - db
#    entrypoint:
#      - ./wait-for-postgres.sh
#      - db

  mlflow_server:
    build:
      context: mlflow-server
      dockerfile: Dockerfile
    environment:
      - PATH_TO_ARTIFACTS=/artifacts
      - PATH_TO_TRACKING=/tracking
      - MLFLOW_PORT=5000
    volumes:
      - mlflow_artifacts:/artifacts
      - /var/metrics/1/mlflow/tracking:/tracking
    ports:
      - "5000:5000"
    restart: always

  tfboard:
    build:
      context: .
      dockerfile: Dockerfile-tfboard

    ports:
      - "6006:6006"

    environment:
      - LOGS_PATH=/var/models/

    volumes:
      - /var/models/:/var/models/

    restart: always

volumes:
  mlflow_artifacts: {}
